---
title: "The Average Goals per Player per Season in the NHL (2008-2018)"
#author: "Fall 2020, JMN420: Jeffrey Yao, Martha Dixon, Nisha Sen"
#date: "Due: Monday, December 14"
output: 
  html_document:
    theme: readable
    toc: yes
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
```


# Introduction

Our goal for this project is to predict within a reasonable amount of confidence the number of goals a player will score in a season using other variables such as assists (A), position (Pos), age, games played (GP), penalty minutes (PIM), time on ice (TOI), blocks (BLK), hits (HIT), and face off wins (FOwin). We excluded any variables in the dataset that were directly related to the number of goals a player had.  We chose to model this data because we are all big hockey fans, and were interested in seeing which variables are most important in predicting the number of goals a player has in a season. 

The dataset that we used in this report can be found [here](http://inalitic.com/datasets/nhl%20player%20data.html).

# Methods

First, we need to load the dataset, and we can take a look at the first and last few observations and name all of the variables.
```{r}
skaters_full = read.csv("skater_stats.csv")
head(skaters_full)
tail(skaters_full)
names(skaters_full)
```

This data set in its entirety is quite large, and encompasses a large time frame, from 1940 until 2018. In order to make this more relevant, we decided to subset the data and only consider observations between 2008 and 2018, as follows.

```{r}
skaters <- subset(skaters_full, Season >= 2008)
```

Next, looking at the structure of our data frame, we can see that we have:

- a lot of numerical observations that R views as character observations, and
- a lot of empty values within each category, which become NA values once we convert variables to numeric. 

```{r}
str(skaters)
```


We amend this by converting the relevant vectors to numeric and setting all of the NA values equal to 0. We can see how this changes the dataset by again checking the structure.

```{r, warning = FALSE}
skaters$Pos <- as.factor(skaters$Pos)
skaters$Age <- as.numeric(skaters$Age)
skaters$GP <- as.numeric(skaters$GP)
skaters$G <- as.numeric(skaters$G)
skaters$GPG <- as.numeric(skaters$GPG)
skaters$A <- as.numeric(skaters$A)
skaters$PTS <- as.numeric(skaters$PTS)
skaters$X... <- as.numeric(skaters$X...)
skaters$PIM <- as.numeric(skaters$PIM)
skaters$EVG <- as.numeric(skaters$EVG)
skaters$PPG <- as.numeric(skaters$PPG)
skaters$SHG <- as.numeric(skaters$SHG)
skaters$GWG <- as.numeric(skaters$GWG)
skaters$EVA <- as.numeric(skaters$EVA)
skaters$PPA <- as.numeric(skaters$PPA)
skaters$SHA <- as.numeric(skaters$SHA)
skaters$S <- as.numeric(skaters$S)
skaters$S. <- as.numeric(skaters$S.)
skaters$TOI <- as.numeric(skaters$TOI)
skaters$BLK <- as.numeric(skaters$BLK)
skaters$HIT <- as.numeric(skaters$HIT)
skaters$FOwin <- as.numeric(skaters$FOwin)
skaters$FOloss <- as.numeric(skaters$FOloss)
skaters$FO. <- as.numeric(skaters$FO.)
```

```{r}
skaters[is.na(skaters)] = 0
str(skaters)
```

As we can see, we have a lot of different predictors to choose from when we consider how to best model the average goals per player. The response variable we are considering, Goals (`G`), is used in the calculations of a few other variables, so we exclude these variables from our consideration. These variables include: 

- `PTS`, points tallied by that player in corresponding season; `PTS` = `G` + `A`
- `GPG`, goals per game by that player in corresponding season
- `EVG`, goals scored by player while team is even strength
- `PPG`, goals scored by player while team is on the powerplay
- `SHG`, goals scored by player while team is on the penalty kill
- `GWG`, game winning goals scored by player in that season
- `S.` or S%, the shooting percentage of player, which is calculated from goals scored (G) divided by the shots taken (S)

We also exclude the variable `X` from our analysis, since it is not included as a variable in the source documentation for our data; this column exists as a descriptor and is a combination of `Season` and `Player`.

We take this into account below, and remove these variables:

```{r}
skaters_cleaned <- skaters[, c(4, 6, 7, 8, 10, 13, 21, 25, 26, 27, 28)]

```

The variables that we are using for our analysis are as follows:

- `Season` - year corresponding to the season stats based on when the season ended (i.e. 2015-2016 equates to 2016)
- `Age` - age of player during that corresponding season of play 
- `Pos` - position played by that player  
- `GP` - number of games played by that player in the corresponding season
- `A` - Assists tallied by that player in the corresponding season
- `PIM` - penalties in minutes given to that player in the season
- `S` - Total number of shots taken by player in the season
- `BLK` - number of blocked shots 
- `HIT` - number of hits
- `FOwin` - number of faceoffs won
- `FOloss` - number of faceoffs lost 


The full additive model(excluding the variables above) can be found in the **Appendix** section.

Before we started testing models, we needed to make sure we were able to check and validate assumptions. We used the following functions to do so graphically:

```{r}
plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
  plot(fitted(model), resid(model), 
       col = pointcol, pch = 20, cex = 1.5,
       xlab = "Fitted", ylab = "Residuals")
  abline(h = 0, col = linecol, lwd = 2)
}

plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
  qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
  qqline(resid(model), col = linecol, lwd = 2)
}

```

Every model we fitted violated the assumptions of constant variance and of normally distributed errors; we attempted to fit the full additive model, a polynomial (squared) model, and models found using AIC based on both of those (code can be found in **Appendix**). We also attempted to transform the predictors using logarithmic transformations, square root transformations, and cube root transformations (omitted for relevance), but all of those models violated assumptions as well.

# Results

After all of this investigation, we decided to select the model we found with the greatest $R^2$ value, which ended up being our polynomial model, or `goals_bigModel`. The adjusted $R^2$ value from the model we found using backwards AIC on this model was the same as the $R^2$ value of this model itself. The model is as follows, along with its $R^2$ value and our attempt to check assumptions:

```{r}
goals_bigModel = lm(G ~. ^ 2 + I(Age ^ 2)  + I(GP ^ 2) + I(A ^ 2) + I(PIM ^ 2) + I(S ^ 2) + I(BLK ^ 2) + I(FOwin ^ 2) + I(FOloss ^ 2), data = skaters_cleaned)
summary(goals_bigModel)$r.sq
```

```{r}
library(lmtest)
plot_fitted_resid(goals_bigModel)
bptest(goals_bigModel)
plot_qq(goals_bigModel)
```

As we can see, our assumptions for constant variance and our assumptions for normality of errors have both been violated.

# Discussion

As we mentioned and displayed in the results section, the assumptions for both constant variance and normality of errors have both been violated. Based upon the residual graph, you can clearly see that it does not follow a constant variance and bubbles out during the middle-fitted values. We also further confirmed that constant variance is violated by utilizing the studentized Breusch-Pagan test. With its small p-value, we reject the null of homoscedasticity. Therefore, the constant variance is violated. Lastly, the Q-Q plot showed that the points did not closely follow the straight line. Therefore the model does violates the assumption of normality. 
 
Although our model had a high R^2 value, it still is not that beneficial to use as a model due to the fact that there are too many issues. First all the assumptions were violated, and our AIC value is also very large. We typically want a smaller AIC value due to the fact it would demonstrate the model is a good fit if the AIC is small. Therefore, we can’t say that the variables we tested would do a good job in estimating the number of goals a NHL player would score each season. Originally, we had thought that some of these variables we picked would be good estimators but after running models, we realized that’s not the case. Some of the variables were not good estimators for the number of goals players would score each season.

Some potential shortcomings we had with our model was the fact that some data were not tracked until much later. For instance, some of the data wasn’t tracked until 2008 which made it a little harder to do models. Another issue we faced when trying to run models was the fact that interaction models took a very long time to run. 


# Appendix

The full additive model:

```{r}
goals_addfull = lm(G ~ ., data = skaters_cleaned)
summary(goals_addfull)$r.sq
```

Interaction models took too long to run with RStudio (even models that used only 2 predictors), so we excluded those from our analysis as well.

In our analysis, we used backwards selection procedures with AIC as our metric, starting on the full additive model:

```{r}
goals_model_back_aic = step(goals_addfull, direction = "backward", trace = 0)
summary(goals_model_back_aic)$adj.r.sq

```

We also searched through the possible models using BIC; the code is included below but will not run when knitting together the .Rmd file, in order to maximize processing efficiency:

```{r, eval=FALSE}
n = length(resid(goals_addfull))
goals_model_back_bic = step(goals_addfull, direction = "backward", k = log(n))
summary(goals_model_back_bic)adj.$r.sq
```

We can see that the model found using AIC is slightly better than the model found using BIC, but the full additive model still yields the highest $R^2$ value.

We considered a polynomial model, with backwards AIC as well (not run to minimize the time taken to knit an html file):

```{r, eval=FALSE}
goals_bigModel = lm(G ~. ^ 2 + I(Age ^ 2)  + I(GP ^ 2) + I(A ^ 2) + I(PIM ^ 2) + I(S ^ 2) + I(BLK ^ 2) + I(FOwin ^ 2) + I(FOloss ^ 2), data = skaters_cleaned)
summary(goals_bigModel)$r.sq
big_model_back_aic = step(goals_bigModel, direction = "backward", trace = 0)
summary(big_model_back_aic)$r.sq
```

Code is not included here for concision, but all assumptions were violated when we attempted to check validity of the assumptions for constant variance and normality of errors, using a combination of the functions included in the **Methods** section and the `bptest()` function.

### Fall 2020, JMN420: Jeffrey Yao, Martha Dixon, Nisha Sen